name: Fraud Detection CI/CD

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  id-token: write

env:
  AWS_REGION: us-east-1
  PYTHON_VERSION: "3.11"
  S3_DATA_URI: s3://safeguard-ml-fraud-detection-pipeline-bronze/Variant II.csv

jobs:
  # =========================================================================
  # Stage 1: Lint & Test — runs on EVERY push/PR
  # No AWS credentials needed. Tests use synthetic fixtures, not real data.
  # =========================================================================
  lint-and-test:
    name: Lint & Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Ruff lint
        run: ruff check src/ app/ tests/

      - name: Ruff format check
        run: ruff format --check src/ app/ tests/

      - name: Run tests
        run: pytest tests/ -v --tb=short --junitxml=test-results.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: test-results.xml

  # =========================================================================
  # Stage 2: Drift Report — runs on PRs only
  # Requires: AWS credentials (to download data from S3)
  # =========================================================================
  drift-report:
    name: Drift Report (CML)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: lint-and-test
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Setup CML
        uses: iterative/setup-cml@v2

      - name: Download data from S3
        run: |
          mkdir -p data
          aws s3 cp "${{ env.S3_DATA_URI }}" "data/Variant II.csv"

      - name: Generate Evidently drift report
        run: |
          python -m src.monitoring \
            --data-path "data/Variant II.csv" \
            --config configs/fraud_config.yaml \
            --report-dir artifacts/reports/

      - name: Post CML comment on PR
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: cml comment update artifacts/reports/drift_summary.md

      - name: Upload drift report
        uses: actions/upload-artifact@v4
        with:
          name: drift-report
          path: artifacts/reports/drift_report.html

  # =========================================================================
  # Stage 3: Train & Evaluate — runs on merge to main
  # Requires: AWS credentials (S3 for data, MLflow for tracking)
  # =========================================================================
  train-and-deploy:
    name: Train & Deploy
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: lint-and-test
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Install dependencies
        run: pip install -e ".[dev]"

      - name: Download data from S3
        run: |
          mkdir -p data
          aws s3 cp "${{ env.S3_DATA_URI }}" "data/Variant II.csv"

      - name: Data integrity gate
        run: python -m src.data_integrity --data-path "data/Variant II.csv"

      - name: Train model
        run: python -m src.train --data-path "data/Variant II.csv" --output-dir artifacts/

      - name: Evaluate model
        run: |
          python -m src.evaluate \
            --model-path artifacts/model.ubj \
            --data-path "data/Variant II.csv" \
            --report-dir artifacts/reports/

      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: evaluation
          path: artifacts/reports/

  # =========================================================================
  # Stage 4: Build & push Docker image — runs after successful training
  # Requires: AWS credentials (ECR push)
  # =========================================================================
  build-and-push:
    name: Build & Push Container
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: train-and-deploy
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push image
        env:
          ECR_REGISTRY: ${{ steps.ecr-login.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/safeguard-ml-fraud-detection-pipeline-inference:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/safeguard-ml-fraud-detection-pipeline-inference:$IMAGE_TAG $ECR_REGISTRY/safeguard-ml-fraud-detection-pipeline-inference:latest
          docker push $ECR_REGISTRY/safeguard-ml-fraud-detection-pipeline-inference:$IMAGE_TAG
          docker push $ECR_REGISTRY/safeguard-ml-fraud-detection-pipeline-inference:latest
